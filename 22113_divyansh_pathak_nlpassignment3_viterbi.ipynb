{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "downloading datasets"
      ],
      "metadata": {
        "id": "uaQvPgt-k3AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/train_data.txt\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/test_data.txt\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/noisy_test_data.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nctaGfek7c3",
        "outputId": "0b261815-1df4-42cd-8476-460d0b27ea87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-18 14:06:32--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/train_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 375849 (367K) [text/plain]\n",
            "Saving to: ‘train_data.txt’\n",
            "\n",
            "train_data.txt      100%[===================>] 367.04K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-03-18 14:06:33 (8.58 MB/s) - ‘train_data.txt’ saved [375849/375849]\n",
            "\n",
            "--2025-03-18 14:06:33--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/test_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77062 (75K) [text/plain]\n",
            "Saving to: ‘test_data.txt’\n",
            "\n",
            "test_data.txt       100%[===================>]  75.26K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-03-18 14:06:33 (3.35 MB/s) - ‘test_data.txt’ saved [77062/77062]\n",
            "\n",
            "--2025-03-18 14:06:33--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/noisy_test_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77120 (75K) [text/plain]\n",
            "Saving to: ‘noisy_test_data.txt’\n",
            "\n",
            "noisy_test_data.txt 100%[===================>]  75.31K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-03-18 14:06:34 (3.40 MB/s) - ‘noisy_test_data.txt’ saved [77120/77120]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading file"
      ],
      "metadata": {
        "id": "hW7CC1NQlCAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            sentence = []\n",
        "            for token in line.strip().split():\n",
        "                word, tag = token.rsplit('/', 1)  # Split word and tag\n",
        "                sentence.append((word, tag))\n",
        "            data.append(sentence)\n",
        "    return data\n",
        "\n",
        "# Load train and test data from files\n",
        "train_data_file = '/content/train_data.txt'  # Path to your training data file\n",
        "test_data_file = '/content/test_data.txt'    # Path to your test data file\n",
        "noisy_test_data_file = '/content/noisy_test_data.txt'  # Path to your noisy test data file\n",
        "\n",
        "train_data = load_data(train_data_file)\n",
        "test_data = load_data(test_data_file)\n",
        "noisy_test_data = load_data(noisy_test_data_file)\n",
        "\n",
        "# Print a sample from the training data\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-7XRbJKM2-j",
        "outputId": "22375edc-5b48-45f0-a4ef-a5212a4f398a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('He', 'PRON'), ('let', 'VERB'), ('her', 'PRON'), ('tell', 'VERB'), ('him', 'PRON'), ('all', 'PRT'), ('about', 'ADP'), ('the', 'DET'), ('church', 'NOUN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Initialize count dictionaries\n",
        "transition_counts = defaultdict(lambda: defaultdict(int))\n",
        "emission_counts = defaultdict(lambda: defaultdict(int))\n",
        "state_counts = defaultdict(int)\n",
        "states = set()\n",
        "\n",
        "# Count occurrences in training data\n",
        "for sentence in train_data:\n",
        "    prev_tag = \"<s>\"  # Start symbol\n",
        "    for word, tag in sentence:\n",
        "        states.add(tag)\n",
        "        transition_counts[prev_tag][tag] += 1\n",
        "        emission_counts[tag][word] += 1\n",
        "        state_counts[tag] += 1\n",
        "        prev_tag = tag\n",
        "    transition_counts[prev_tag][\"</s>\"] += 1  # End symbol\n",
        "\n",
        "states = list(states)\n",
        "\n",
        "# Compute probabilities\n",
        "def compute_probabilities(transition_counts, emission_counts, state_counts):\n",
        "    transition_probs = defaultdict(lambda: defaultdict(float))\n",
        "    emission_probs = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "    # Compute transition probabilities\n",
        "    for prev_state, next_states in transition_counts.items():\n",
        "        total = sum(next_states.values())\n",
        "        for next_state, count in next_states.items():\n",
        "            transition_probs[prev_state][next_state] = count / total\n",
        "\n",
        "    # Compute emission probabilities\n",
        "    for state, words in emission_counts.items():\n",
        "        total = state_counts[state]\n",
        "        for word, count in words.items():\n",
        "            emission_probs[state][word] = count / total\n",
        "\n",
        "    return transition_probs, emission_probs\n",
        "\n",
        "# Get probabilities\n",
        "transition_probs, emission_probs = compute_probabilities(transition_counts, emission_counts, state_counts)\n",
        "\n",
        "# Print sample probabilities\n",
        "print(f\"Sample transition probability: {list(transition_probs.items())[:1]}\")\n",
        "print(f\"Sample emission probability: {list(emission_probs.items())[:1]}\")\n"
      ],
      "metadata": {
        "id": "6fBG2exLhAh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e5f8f9-e7fc-459b-f0e0-2febf38646f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample transition probability: [('<s>', defaultdict(<class 'float'>, {'PRON': 0.149, 'NOUN': 0.1505, 'ADV': 0.0965, 'DET': 0.201, 'ADP': 0.1345, '.': 0.083, 'PRT': 0.031, 'VERB': 0.0485, 'ADJ': 0.0365, 'NUM': 0.016, 'CONJ': 0.053, 'X': 0.0005}))]\n",
            "Sample emission probability: [('PRON', defaultdict(<class 'float'>, {'He': 0.06112759643916914, 'her': 0.024925816023738872, 'him': 0.04925816023738872, 'it': 0.13887240356083086, 'It': 0.035014836795252226, 'You': 0.011869436201780416, 'We': 0.01543026706231454, 'you': 0.05934718100890208, 'he': 0.13353115727002968, 'they': 0.05459940652818991, 'them': 0.037388724035608306, 'we': 0.03798219584569733, 'who': 0.052818991097922846, 'I': 0.09495548961424333, 'me': 0.02373887240356083, 'himself': 0.012462908011869436, 'She': 0.018991097922848664, 'yourself': 0.002967359050445104, 'she': 0.035014836795252226, \"'im\": 0.0005934718100890207, 'They': 0.013056379821958458, 'us': 0.013649851632047478, 'that': 0.037388724035608306, 'themselves': 0.00830860534124629, 'Whom': 0.0005934718100890207, 'his': 0.0011869436201780415, \"'em\": 0.0005934718100890207, 'myself': 0.004154302670623145, 'herself': 0.0035608308605341245, 'Who': 0.0011869436201780415, 'oneself': 0.0005934718100890207, 'hers': 0.0005934718100890207, 'itself': 0.004747774480712166, 'yow': 0.0011869436201780415, 'ye': 0.0005934718100890207, 'thee': 0.0005934718100890207, 'thou': 0.0005934718100890207, 'whom': 0.002967359050445104, 'yourselves': 0.0005934718100890207, 'Me': 0.0005934718100890207, 'ourselves': 0.0011869436201780415, 'mine': 0.0005934718100890207, 'ours': 0.0005934718100890207}))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_algorithm(sentence, states, transition_probs, emission_probs):\n",
        "    V = [{}]  # Stores probabilities\n",
        "    path = {}  # Stores the best path\n",
        "\n",
        "    # Initialize base case (t=0)\n",
        "    for state in states:\n",
        "        V[0][state] = transition_probs[\"<s>\"].get(state, 1e-6) * emission_probs[state].get(sentence[0], 1e-6)\n",
        "        path[state] = [state]\n",
        "\n",
        "    # Recursively compute probabilities for t > 0\n",
        "    for t in range(1, len(sentence)):\n",
        "        V.append({})\n",
        "        new_path = {}\n",
        "\n",
        "        for curr_state in states:\n",
        "            max_prob, best_prev_state = max(\n",
        "                (V[t - 1][prev_state] * transition_probs[prev_state].get(curr_state, 1e-6) *\n",
        "                 emission_probs[curr_state].get(sentence[t], 1e-6), prev_state)\n",
        "                for prev_state in states\n",
        "            )\n",
        "            V[t][curr_state] = max_prob\n",
        "            new_path[curr_state] = path[best_prev_state] + [curr_state]\n",
        "\n",
        "        path = new_path\n",
        "\n",
        "    # Find the best final state\n",
        "    max_prob, best_final_state = max((V[-1][state] * transition_probs[state].get(\"</s>\", 1e-6), state) for state in states)\n",
        "    return path[best_final_state]\n",
        "\n",
        "# Example test sentence\n",
        "test_sentence = [\"The\", \"dog\", \"barks\"]\n",
        "predicted_tags = viterbi_algorithm(test_sentence, states, transition_probs, emission_probs)\n",
        "print(\"Predicted POS Tags:\", predicted_tags)\n"
      ],
      "metadata": {
        "id": "egzJoO7WhAf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c533a37c-ea5b-4208-c150-001d2131f44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted POS Tags: ['DET', 'NOUN', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to decode noisy sentences\n",
        "def decode_noisy_data(noisy_sentences, states, transition_probs, emission_probs):\n",
        "    decoded_sentences = []\n",
        "    for sentence in noisy_sentences:\n",
        "        words = [word for word, _ in sentence]  # Extract words from noisy sentences\n",
        "        predicted_tags = viterbi_algorithm(words, states, transition_probs, emission_probs)\n",
        "        decoded_sentences.append(list(zip(words, predicted_tags)))\n",
        "    return decoded_sentences\n",
        "\n",
        "# Decode noisy test sentences\n",
        "decoded_noisy_sentences = decode_noisy_data(noisy_test_data, states, transition_probs, emission_probs)\n",
        "\n",
        "# Print some decoded sentences\n",
        "for i in range(5):  # Display the first 5 results\n",
        "    print(decoded_noisy_sentences[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0kjCrwIhRK3",
        "outputId": "f7e5f77c-9bca-40ca-8d8d-2b26f1fc1580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Get', 'DET'), ('copper', 'NOUN'), ('or', 'CONJ'), ('earthenware', 'NOUN'), ('mugs', 'ADP'), ('that', 'PRON'), ('keep', 'VERB'), ('beer', 'NOUN'), ('chilled', '.'), ('or', 'CONJ'), ('soup', 'NOUN'), ('hot', 'ADJ'), ('.', '.')]\n",
            "[('By', 'ADP'), ('permitting', 'DET'), ('freshman', 'ADJ'), ('students', 'NOUN'), ('we', 'PRON'), ('might', 'VERB'), ('extend', 'VERB'), ('the', 'DET'), ('opportunity', 'NOUN'), ('for', 'ADP'), ('such', 'PRT'), ('a', 'DET'), ('course', 'NOUN'), ('to', 'ADP'), ('some', 'DET'), ('individuals', 'NOUN'), ('who', 'PRON'), ('otherwise', 'ADV'), ('might', 'VERB'), ('never', 'ADV'), ('get', 'VERB'), ('to', 'PRT'), ('take', 'VERB'), ('it', 'PRON'), ('.', '.')]\n",
            "[('In', 'ADP'), ('stating', 'ADP'), ('this', 'DET'), ('position', 'NOUN'), (',', '.'), ('we', 'PRON'), ('should', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('make', 'VERB'), ('it', 'PRON'), ('clear', 'ADJ'), ('to', 'ADP'), ('you', 'PRON'), ('that', 'ADP'), ('we', 'PRON'), ('cannot', 'VERB'), ('expect', 'VERB'), ('artists', 'NOUN'), ('and', 'CONJ'), ('intellectuals', 'NOUN'), ('in', 'ADP'), ('other', 'ADJ'), ('lands', 'NOUN'), ('to', 'ADP'), ('share', 'NOUN'), ('our', 'DET'), ('opinion', 'NOUN'), ('in', 'ADP'), ('every', 'DET'), ('respect', 'NOUN'), ('.', '.')]\n",
            "[('Demagogues', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('sort', 'NOUN'), ('found', 'VERB'), ('communist', 'ADP'), ('bogeys', 'DET'), ('lurking', 'NOUN'), ('behind', 'ADP'), ('any', 'DET'), ('new', 'ADJ'), ('idea', 'NOUN'), ('that', 'PRON'), ('would', 'VERB'), ('run', 'VERB'), ('counter', 'VERB'), ('to', 'ADP'), ('stereotyped', 'DET'), ('notions', 'NOUN'), ('.', '.')]\n",
            "[('Since', 'ADP'), ('ordinary', 'ADJ'), ('breakfast-table', 'NOUN'), ('conversation', 'NOUN'), ('was', 'VERB'), ('impossible', 'NOUN'), (',', '.'), ('it', 'PRON'), ('was', 'VERB'), ('at', 'ADP'), ('least', 'ADJ'), ('something', 'NOUN'), ('that', 'ADP'), ('they', 'PRON'), ('were', 'VERB'), ('able', 'ADJ'), ('to', 'PRT'), ('offer', 'VERB'), ('Eugene', 'NOUN'), ('the', 'DET'), ('sugar', 'ADJ'), ('bowl', 'NOUN'), ('with', 'ADP'), ('their', 'DET'), ('sugar', 'NOUN'), ('in', 'ADP'), ('it', 'PRON'), (',', '.'), ('and', 'CONJ'), ('the', 'DET'), ('plate', 'NOUN'), ('of', 'ADP'), ('bread', 'NOUN'), ('and', 'CONJ'), ('butter', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('that', 'DET'), ('Eugene', 'NOUN'), ('could', 'VERB'), ('return', 'NOUN'), ('the', 'DET'), ('pitcher', 'NOUN'), ('of', 'ADP'), ('hot', 'ADJ'), ('milk', 'NOUN'), ('to', 'ADP'), ('them', 'PRON'), ('handle', 'VERB'), ('first', 'ADV'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation\n",
        "An example of evaluation:"
      ],
      "metadata": {
        "id": "23eBoIIph4lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [('Get', 'VERB'), ('copper', 'NOUN'), ('or', 'CONJ'), ('earthenware', 'NOUN'), ('mugs', 'NOUN'), ('that', 'PRON'), ('keep', 'VERB'), ('beer', 'NOUN'), ('chilled', 'VERB'), ('or', 'CONJ'), ('soup', 'NOUN'), ('hot', 'ADJ'), ('.', '.')]\n",
        "predicted_tags = ['DET', 'NOUN', 'CONJ', 'NOUN', 'ADP', 'PRON', 'VERB', 'NOUN', '.', 'CONJ', 'NOUN', 'ADJ', '.']\n",
        "true_tags = ('VERB', 'NOUN', 'CONJ', 'NOUN', 'NOUN', 'PRON', 'VERB', 'NOUN', 'VERB', 'CONJ', 'NOUN', 'ADJ', '.')\n",
        "correct = 0\n",
        "total = 0\n",
        "correct += sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
        "total += len(true_tags)\n",
        "accuracy = correct / total\n",
        "\n",
        "print(f\"Baseline Viterbi Accuracy: {accuracy * 100:.2f}%\")\n",
        "# print(f\"Viterbi with Noise Handling Accuracy: {accuracy * 100:.2f}%\")  # similarly calculate for Noise Handling\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWy2eyhCfr4S",
        "outputId": "cb5cfb8e-fefd-4205-86e5-bfcc73d78721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Viterbi Accuracy: 76.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate accuracy\n",
        "def evaluate_accuracy(test_data, states, transition_probs, emission_probs):\n",
        "    correct = total = 0\n",
        "    for sentence in test_data:\n",
        "        words, true_tags = zip(*sentence)  # Extract words and their actual tags\n",
        "        predicted_tags = viterbi_algorithm(words, states, transition_probs, emission_probs)\n",
        "        correct += sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
        "        total += len(true_tags)\n",
        "    return correct / total\n",
        "\n",
        "# Compute accuracy on test data\n",
        "accuracy = evaluate_accuracy(test_data, states, transition_probs, emission_probs)\n",
        "print(f\"Baseline Viterbi Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compute accuracy on noisy test data\n",
        "noisy_accuracy = evaluate_accuracy(noisy_test_data, states, transition_probs, emission_probs)\n",
        "print(f\"Noise-Handled Viterbi Accuracy: {noisy_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B32h-CgYhdP6",
        "outputId": "208d0988-b8da-4930-a8ef-28736b7887a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Viterbi Accuracy: 90.18%\n",
            "Noise-Handled Viterbi Accuracy: 81.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7nH7DessOTSd"
      }
    }
  ]
}